{
  "config": "traj_results/trajectory_q_gd_50k/config.json",
  "method": "gd",
  "feature_extractor": "polynomial",
  "learning_rate": 1e-05,
  "discount_factor": 0.99,
  "lr_decay": 1,
  "epsilon": 0,
  "epsilon_decay": 1,
  "min_epsilon": 0,
  "min_lr": 1e-05,
  "batch_size": 32,
  "update_freq": 1,
  "min_episodes": 50000,
  "validate_freq": 50,
  "save_model_freq": 10,
  "poly_degree": 3,
  "grad_clip": 1,
  "early_stopping_patience": 10000000000000000000000000000000000000000000,
  "early_stopping_threshold": 0,
  "save_name": "trajectory_q_gd_50k",
  "wandb_name": "trajectory_q_gd_50k",
  "wandb_project": "Q Learning Experiments",
  "use_wandb": true,
  "pretrained_model": "/home/sancar/Improving-Policy-Learning-with-Gradient-Stopping/current_q_learning/traj_results/best_model.pt",
  "num_trajectories": 10,
  "trajectory_shift_threshold": 0.035,
  "max_episodes_per_trajectory": 50000,
  "episodes": 500000,
  "seed": 42
}